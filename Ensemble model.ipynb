{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 0-1: truncated \\UXXXXXXXX escape (<ipython-input-9-7af0ec340793>, line 201)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-9-7af0ec340793>\"\u001b[1;36m, line \u001b[1;32m201\u001b[0m\n\u001b[1;33m    data = pd.read_excel('\\Users\\abrar\\OneDrive\\سطح المكتب/final.xlsx')\u001b[0m\n\u001b[1;37m                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 0-1: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "##########################SVM Model####################################\n",
    "#import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#load the sample data from sample.xlsx file\n",
    "data = pd.read_excel('final.xlsx')\n",
    "\n",
    "#Dependent and independent features\n",
    "x=data['Synopsis']\n",
    "y=data['Risk level']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=0)\n",
    "\n",
    "#Training and testing data\n",
    "print(\"Training data SVM model\\n\\n\",X_train,\"\\n\\n\",y_train)\n",
    "print(\"\")\n",
    "print(\"Testing data for SVM model\\n\\n\",X_test)\n",
    "\n",
    "#pre-processing\n",
    "#Initialize the TF-IDF vectorizer\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, max_df=0.95, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')\n",
    "\n",
    "#transform independent variable using TF-IDF vectorizer\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "#Build the SVM model\n",
    "SVM_model = LinearSVC()\n",
    "\n",
    "#Use calibrated classifier for calculate test probability\n",
    "clf1 = CalibratedClassifierCV(SVM_model)\n",
    "\n",
    "#Fit train and test into the model\n",
    "clf1.fit(X_train_tfidf, y_train)\n",
    "\n",
    "#Predict the result\n",
    "y_pred1 = clf1.predict(X_test_tfidf)\n",
    "\n",
    "#Evaluate the model# Creating the Confusion Matrix\n",
    "#cm = confusion_matrix(y_test, y_pred1)\n",
    "\n",
    "#print(\"\\n\",\"Confusion matrix SVM model\\n\")\n",
    "#fig, ax = plt.subplots(figsize=(7,5))\n",
    "#sns.heatmap(cm, annot=True, fmt='d')\n",
    "#plt.show()\n",
    "#print(\"\\n\")\n",
    "#print(\"Classification report for SVM model\\n\")\n",
    "#print(classification_report(y_test, y_pred1))\n",
    "#print(\"\\n\")\n",
    "#print()\n",
    "#print(\"Accuracy score of SVM model\",round(accuracy_score(y_test, y_pred1),2)*100)\n",
    "#print(\"\\n\")\n",
    "\n",
    "##########################Naive Bayes Model####################################\n",
    "#import necessary libraries\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#Build the classifier\n",
    "clf2 = MultinomialNB()\n",
    "\n",
    "#Fit train and test into the model\n",
    "clf2.fit(X_train_tfidf, y_train)\n",
    "\n",
    "#Predict the result\n",
    "y_pred2 = clf2.predict(X_test_tfidf)\n",
    "\n",
    "#Evaluate the model# Creating the Confusion Matrix\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "#cm = confusion_matrix(y_test, y_pred2)\n",
    "\n",
    "#print(\"\\n\",\"Confusion matrix Naive Bayes model\\n\")\n",
    "#fig, ax = plt.subplots(figsize=(7,5))\n",
    "#sns.heatmap(cm, annot=True, fmt='d')\n",
    "#plt.show()\n",
    "#print(\"\\n\")\n",
    "#print(\"Classification report for Naive Bayes model\\n\")\n",
    "#print(classification_report(y_test, y_pred2))\n",
    "#print(\"\\n\")\n",
    "#print()\n",
    "#print(\"Accuracy score of Naive Bayes model\",round(accuracy_score(y_test, y_pred2),2)*100)\n",
    "#print(\"\\n\")\n",
    "\n",
    "###################################MaxEnt Model###############################\n",
    "#import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "def formatop(x,y):\n",
    "    ind1=x.index\n",
    "    format1=[]\n",
    "    fortup=()\n",
    "    for i in ind1:\n",
    "        textup=x[i].split()\n",
    "        fortup=(textup,y[i])\n",
    "        format1.append(fortup)\n",
    "    return(format1)\n",
    "\n",
    "def list_to_dict(words_list):\n",
    "    return dict([(word, True) for word in words_list])\n",
    "\n",
    "train_data=formatop(X_train,y_train)\n",
    "test_data=formatop(X_test,y_test)\n",
    " \n",
    "training_set_formatted = [(list_to_dict(element[0]), element[1]) for element in train_data]\n",
    "\n",
    "import nltk\n",
    "numIterations = 10\n",
    " \n",
    "algorithm = nltk.classify.MaxentClassifier.ALGORITHMS[1]\n",
    "classifier = nltk.MaxentClassifier.train(training_set_formatted, algorithm, max_iter=numIterations)\n",
    "#classifier.show_most_informative_features(10)\n",
    "\n",
    "test_set_formatted = [(list_to_dict(element[0]), element[1]) for element in test_data] \n",
    "\n",
    "y_pred3=[]\n",
    "y_test=[]\n",
    "for i in range(0,len(test_data)):\n",
    "    y_test.append(test_set_formatted[i][1])\n",
    "    text = test_set_formatted[i][0]\n",
    "    y_pred3.append(classifier.classify(text))    \n",
    "print(\"\\n\")\n",
    "#Conf_Mat = metrics.confusion_matrix(y_test,y_pred3)\n",
    "#print(\"The confusion matrix is\\n\\n\",Conf_Mat)\n",
    "\n",
    "#classification report\n",
    "#print(\"Classification report\\n\",metrics.classification_report(y_test,y_pred3))\n",
    "#print(\"Accuracy score : \",metrics.accuracy_score(y_test,y_pred3)*100)\n",
    "\n",
    "#################################Ensemble model######################\n",
    "\n",
    "#Training and testing data\n",
    "print(\"Training data of Ensemble model\\n\\n\",X_train,\"\\n\\n\",y_train)\n",
    "print(\"\\n\")\n",
    "print(\"Testing data of Ensemble model\\n\\n\",X_test)\n",
    "print(\"\\n\")\n",
    "\n",
    "#store all predictions\n",
    "frame = [y_pred1,y_pred2,y_pred3]\n",
    "df3 = pd.DataFrame(frame)\n",
    "\n",
    "#find prediction mode from all three classifiers\n",
    "En_pred = df3.mode().loc[0]\n",
    "print(\"Classification report of Ensemble model\\n\")\n",
    "print(classification_report(y_test, En_pred))\n",
    "\n",
    "print(\"Confusion matrix of ensemble model\\n\")\n",
    "print(confusion_matrix(y_test, En_pred))\n",
    "print(\"\\n\")\n",
    "\n",
    "#test our model on the test data\n",
    "print(\"Accuracy score of ensemble model : \",metrics.accuracy_score(y_test, En_pred)*100)\n",
    "print(\"\\n\")\n",
    "\n",
    "#plot precision recall graph\n",
    "plt.rcParams[\"figure.figsize\"] = [16,10]\n",
    "import scikitplot as skplt\n",
    "probas = clf1.predict_proba(X_test_tfidf)\n",
    "skplt.metrics.plot_precision_recall(y_test, probas)\n",
    "plt.title(\"Precision & Recall graph for Ensemble model\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "############################RNN Model#################################\n",
    "#import necessary libraries\n",
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'theano'\n",
    "import time\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers import Flatten\n",
    "from keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "#load the sample data from sample.xlsx file\n",
    "data = pd.read_excel('\\Users\\abrar\\OneDrive\\سطح المكتب/final.xlsx')\n",
    "\n",
    "#Make it as a data frame\n",
    "df = pd.DataFrame(data)\n",
    "#print(df.columns)\n",
    "\n",
    "#Convert string into numbers\n",
    "df1 = df.apply(lambda s: s.map({k:i for i,k in enumerate(s.unique())}))\n",
    "\n",
    "co = df1.corr(method='pearson')\n",
    "#print(co)\n",
    "\n",
    "a = df1[['Date', 'Local Time Of Day','Crew Size','Aircraft Operator','Light','Operating Under FAR Part','Flight Plan', 'Mission', 'Flight Phase','Location Of Person','Human Factors','Anomaly', 'Detector','When Detected', 'Result', 'Contributing Factors / Situations','Primary Problem','Risk level']]\n",
    "\n",
    "b = df['Risk level']\n",
    "\n",
    "final = [a,b]\n",
    "\n",
    "#Concatenate the independent and dependent variables\n",
    "finaldf = pd.concat(final,axis=1)\n",
    "\n",
    "#feature selection\n",
    "X1 = finaldf.iloc[:,0:17]\n",
    "y1 = finaldf.iloc[:,17]\n",
    "\n",
    "#Split the data into train and testing\n",
    "X_train1, X_test1, Y_train1, Y_test1 = train_test_split(X1, y1, test_size=0.1, random_state=0)\n",
    "\n",
    "#Print training data\n",
    "print(\"Training data\\n\",X_train1,\"\\n\",Y_train1)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "#Print testing data\n",
    "print(\"Testing data\\n\",X_test1)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "#make dependent variable categorical\n",
    "Y_train1 = np_utils.to_categorical(Y_train1,num_classes=3)\n",
    "Y_test1 = np_utils.to_categorical(Y_test1,num_classes=3)\n",
    "\n",
    "embed_dim = 128\n",
    "lstm_out = 300\n",
    "batch_size = 50\n",
    "\n",
    "#Build Recurrent neural networks\n",
    "model = Sequential()\n",
    "model.add(Embedding(2500, embed_dim,input_length = X_train1.shape[1]))\n",
    "model.add(LSTM(lstm_out))\n",
    "model.add(Dense(3,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "#Here we train the Network.\n",
    "start_time = time.time()\n",
    "model.fit(X_train1, Y_train1, batch_size = batch_size, epochs = 5,  verbose = 2)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(\"Time to train model: %.3f seconds\" % elapsed_time)\n",
    "\n",
    "start_time = time.time()\n",
    "score,acc = model.evaluate(X_test1,Y_test1,verbose = 2,batch_size = batch_size)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(\"Time to evaluate model: %.3f seconds\" % elapsed_time)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "#Predict the test results\n",
    "prediction = model.predict(X_test1)\n",
    "length = len(prediction)\n",
    "y_label = np.argmax(Y_test1,axis=1)\n",
    "predict_label = np.argmax(prediction,axis=1)\n",
    "\n",
    "#classification report\n",
    "print(\"Confusion Matrix of RNN\\n\",confusion_matrix(y_label,predict_label))\n",
    "print(\"\\n\")\n",
    "print(\"Classification Report of RNN\\n\",classification_report(y_label,predict_label))\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy : \",(accuracy_score(y_label,predict_label)*100))\n",
    "print(\"\\n\")\n",
    "\n",
    "#Precision-recall graph\n",
    "plt.rcParams[\"figure.figsize\"] = [16,10]\n",
    "import scikitplot as skplt\n",
    "probas = model.predict_proba(X_test1)\n",
    "skplt.metrics.plot_precision_recall(y_label, probas)\n",
    "plt.title(\"Precision & Recall graph for RNN model\")\n",
    "plt.show()\n",
    "\n",
    "#predict classes for test data\n",
    "RNN_y_pred = model.predict_classes(X_test1)\n",
    "\n",
    "##################################Final model########################\n",
    "#store all predictions  \n",
    "frame1 = [En_pred,RNN_y_pred]\n",
    "df4 = pd.DataFrame(frame1)\n",
    "\n",
    "#final prediction from Ensemble and RNN\n",
    "fl_pred = df4.loc[0]\n",
    "\n",
    "#Classification report\n",
    "print(\"Classification report of combined model\\n\")\n",
    "print(classification_report(y_test, fl_pred))\n",
    "\n",
    "#Accuracy\n",
    "a = (metrics.accuracy_score(y_test, fl_pred)*100)\n",
    "print(\"Accuracy of the combined model : \",round(a))\n",
    "\n",
    "#plot precision recall graph\n",
    "plt.rcParams[\"figure.figsize\"] = [16,10]\n",
    "import scikitplot as skplt\n",
    "probas = clf1.predict_proba(X_test_tfidf)\n",
    "skplt.metrics.plot_precision_recall(y_test, probas)\n",
    "plt.title(\"Precision & Recall graph for Combined model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-a9fcd54b25e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'f' is not defined"
     ]
    }
   ],
   "source": [
    "f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
